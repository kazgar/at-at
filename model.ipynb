{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "''' SET THE DEVICE '''\n",
    "device = 'mps' if torch.mps.is_available() else 'cpu'\n",
    "device = 'cuda' if torch.cuda.is_available() else device\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kazikgarstecki/Desktop/Y2S2/as_project/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' UNCOMMENT THE FOLLOWING LINES TO DOWNLOAD DATASET '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "''' UNCOMMENT THE FOLLOWING LINES TO DOWNLOAD DATASET '''\n",
    "#path = kagglehub.dataset_download('mostafaabla/garbage-classification')\n",
    "#print('path to dataset files', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All catgories of garbage classification dataset\n",
      "----------------------------------------------------\n",
      "paper\n",
      "green-glass\n",
      "clothes\n",
      "metal\n",
      "cardboard\n",
      "trash\n",
      "biological\n",
      "white-glass\n",
      "battery\n",
      "brown-glass\n",
      "plastic\n",
      "shoes\n"
     ]
    }
   ],
   "source": [
    "dir_path = os.path.join(os.getcwd(), 'data/garbage_classification/')\n",
    "\n",
    "print('All catgories of garbage classification dataset')\n",
    "print('----------------------------------------------------')\n",
    "for file in os.listdir(dir_path):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1050/1050 [00:03<00:00, 306.22it/s]\n",
      "100%|██████████| 629/629 [00:02<00:00, 272.64it/s]\n",
      "100%|██████████| 769/769 [00:02<00:00, 295.66it/s]\n",
      "100%|██████████| 891/891 [00:02<00:00, 305.69it/s]\n",
      "100%|██████████| 697/697 [00:02<00:00, 316.55it/s]\n",
      "100%|██████████| 985/985 [00:03<00:00, 266.12it/s]\n",
      "100%|██████████| 775/775 [00:02<00:00, 314.05it/s]\n",
      "100%|██████████| 607/607 [00:02<00:00, 279.44it/s]\n",
      "100%|██████████| 865/865 [00:02<00:00, 309.93it/s]\n"
     ]
    }
   ],
   "source": [
    "data_dict = {directory_name: [] for directory_name in os.listdir(dir_path)}\n",
    "\n",
    "data_path = Path('data/garbage_classification/')\n",
    "\n",
    "categories_to_include = [\n",
    "    'cardboard',\n",
    "    'green-glass',\n",
    "    'white-glass',\n",
    "    'brown-glass',\n",
    "    'metal',\n",
    "    'paper',\n",
    "    'plastic',\n",
    "    'trash',\n",
    "    'biological'\n",
    "]\n",
    "\n",
    "for category_name in data_dict.keys():\n",
    "    if category_name in categories_to_include:\n",
    "        image_dir = data_path / category_name\n",
    "        for image in tqdm(os.listdir(image_dir)):\n",
    "            img = Image.open(image_dir / image)\n",
    "            img = img.resize((512, 512))\n",
    "            data_dict[category_name].append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050 images in paper directory\n",
      "629 images in green-glass directory\n",
      "Removed clothes directory and its contents.\n",
      "769 images in metal directory\n",
      "891 images in cardboard directory\n",
      "697 images in trash directory\n",
      "985 images in biological directory\n",
      "775 images in white-glass directory\n",
      "Removed battery directory and its contents.\n",
      "607 images in brown-glass directory\n",
      "865 images in plastic directory\n",
      "Removed shoes directory and its contents.\n"
     ]
    }
   ],
   "source": [
    "for category_name in os.listdir(Path('data/garbage_classification/')):\n",
    "    if category_name not in categories_to_include:\n",
    "        shutil.rmtree(data_path / category_name)\n",
    "        print(f\"Removed {category_name} directory and its contents.\")\n",
    "    else:\n",
    "        print(len(os.listdir(data_path / category_name)), 'images in', category_name, 'directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.Lambda(lambda x: x.permute(1, 2, 0)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_dataset = Path('train_test_dataset/garbage_classification')\n",
    "if not os.path.exists(train_test_dataset):\n",
    "    os.makedirs(train_test_dataset)\n",
    "    for train_test in ['train', 'test']:\n",
    "        if not os.path.exists(train_test_dataset / train_test):\n",
    "            os.makedirs(train_test_dataset / train_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: cardboard 891\n",
      "712 images in train set\n",
      "179 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:03<00:25,  3.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: green-glass 629\n",
      "503 images in train set\n",
      "126 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:04<00:16,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: white-glass 775\n",
      "620 images in train set\n",
      "155 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:07<00:13,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: brown-glass 607\n",
      "485 images in train set\n",
      "122 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:08<00:10,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: metal 769\n",
      "615 images in train set\n",
      "154 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:10<00:06,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: paper 1050\n",
      "840 images in train set\n",
      "210 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:12<00:06,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: plastic 865\n",
      "692 images in train set\n",
      "173 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:14<00:04,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: trash 697\n",
      "557 images in train set\n",
      "140 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:15<00:01,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in category: biological 985\n",
      "788 images in train set\n",
      "197 images in test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:17<00:00,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "for category_name in tqdm(categories_to_include):\n",
    "    image_dir = data_path / category_name\n",
    "    all_images = os.listdir(image_dir)\n",
    "    img = Image.open(image_dir / all_images[0])\n",
    "    train_images = random.sample(all_images, int(len(all_images) * 0.8))\n",
    "    print('Number of images in category:', category_name, len(all_images))\n",
    "    print(len(train_images), 'images in train set')\n",
    "    test_images = list(set(all_images) - set(train_images))\n",
    "    print(len(test_images), 'images in test set')\n",
    "    for image in train_images:\n",
    "        path_to_move = train_test_dataset/ 'train' / category_name\n",
    "        if not os.path.exists(path_to_move):\n",
    "            os.makedirs(path_to_move)\n",
    "        img_path = image_dir / image\n",
    "        shutil.copy(img_path, path_to_move)\n",
    "    for image in test_images:\n",
    "        path_to_move = train_test_dataset / 'test' / category_name\n",
    "        if not os.path.exists(path_to_move):\n",
    "            os.makedirs(path_to_move)\n",
    "        img_path = image_dir / image\n",
    "        shutil.copy(img_path, path_to_move)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paper\n",
      "840\n",
      "210\n",
      "green-glass\n",
      "503\n",
      "126\n",
      "metal\n",
      "615\n",
      "154\n",
      "cardboard\n",
      "712\n",
      "179\n",
      "trash\n",
      "557\n",
      "140\n",
      "biological\n",
      "788\n",
      "197\n",
      "white-glass\n",
      "620\n",
      "155\n",
      "brown-glass\n",
      "485\n",
      "122\n",
      "plastic\n",
      "692\n",
      "173\n"
     ]
    }
   ],
   "source": [
    "for directory_name in os.listdir(Path('data/garbage_classification')):\n",
    "    print(directory_name)\n",
    "    print(len(os.listdir(train_test_dataset / 'train' / directory_name)))\n",
    "    print(len(os.listdir(train_test_dataset / 'test' / directory_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset ImageFolder\n",
       "     Number of datapoints: 5812\n",
       "     Root location: train_test_dataset/garbage_classification/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                Lambda()\n",
       "                ToTensor()\n",
       "            ),\n",
       " Dataset ImageFolder\n",
       "     Number of datapoints: 1456\n",
       "     Root location: train_test_dataset/garbage_classification/test\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                Resize(size=(64, 64), interpolation=bilinear, max_size=None, antialias=True)\n",
       "                Lambda()\n",
       "                ToTensor()\n",
       "            ))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = datasets.ImageFolder(root = Path('train_test_dataset/garbage_classification/train'),\n",
    "                                    transform=simple_transform,\n",
    "                                    target_transform=None)\n",
    "test_dataset = datasets.ImageFolder(root = Path('train_test_dataset/garbage_classification/test'),\n",
    "                                    transform=simple_transform)\n",
    "\n",
    "train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['biological',\n",
       " 'brown-glass',\n",
       " 'cardboard',\n",
       " 'green-glass',\n",
       " 'metal',\n",
       " 'paper',\n",
       " 'plastic',\n",
       " 'trash',\n",
       " 'white-glass']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biological': 0,\n",
       " 'brown-glass': 1,\n",
       " 'cardboard': 2,\n",
       " 'green-glass': 3,\n",
       " 'metal': 4,\n",
       " 'paper': 5,\n",
       " 'plastic': 6,\n",
       " 'trash': 7,\n",
       " 'white-glass': 8}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dict = train_dataset.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5812, 1456)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
